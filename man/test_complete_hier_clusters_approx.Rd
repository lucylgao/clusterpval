% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trunc_inf.R
\name{test_complete_hier_clusters_approx}
\alias{test_complete_hier_clusters_approx}
\title{Monte Carlo significance test for complete linkage hierarchical clustering}
\usage{
test_complete_hier_clusters_approx(
  X,
  hcl,
  K,
  k1,
  k2,
  iso = TRUE,
  sig = NULL,
  SigInv = NULL,
  ndraws = 2000
)
}
\arguments{
\item{X}{\eqn{n} by \eqn{p} matrix containing numeric data.}

\item{hcl}{An object of the type \code{hclust} containing the hierarchical clustering of X.}

\item{K}{Integer selecting the total number of clusters.}

\item{k1, k2}{Integers selecting the clusters to test.}

\item{iso}{Boolean. If \code{TRUE}, isotropic covariance matrix model, otherwise not.}

\item{sig}{Optional scalar specifying \eqn{\sigma}, relevant if \code{iso} is \code{TRUE}.}

\item{SigInv}{Optional matrix specifying \eqn{\Sigma^{-1}}, relevant if \code{iso} is \code{FALSE}.}

\item{ndraws}{Integer selecting the number of importance samples, default of 2000.}
}
\value{
\item{stat}{the test statistic: the Euclidean distance between the mean of cluster \code{k1} and the mean of cluster \code{k2}  }
\item{pval}{the approximate p-value}
\item{stderr}{estimated standard error of the p-value estimate}
}
\description{
This tests the null hypothesis of no difference in means between 
clusters \code{k1} and \code{k2} at level \code{K} in a complete 
linkage hierarchical clustering. (The \code{K} clusters are numbered as per 
the results of the \code{cutree} function in the \code{stats} package.)
}
\details{
Important note: Before calling \code{hclust} and this function, make sure to 
load the package \code{fastcluster}. This is because the p-value approximation 
procedure requires running hierarchical clustering on a large number of simulated 
data sets, and the version of \code{hclust} in the \code{fastcluster} package
is much faster than the version of \code{hclust} in \code{stats}.  

In order to account for the fact that the clusters have been estimated from the data, 
the p-values are computed conditional on the fact that those clusters were estimated. 
This function approximates p-values via importance sampling. 

Currently, this function supports squared Euclidean distance as a measure of dissimilarity 
between observations. (Note that complete linkage is invariant under monotone transformations 
of the measure of dissimilarity between observations, so unsquared Euclidean distance 
would produce the same hierarchical clustering.)

By default, this function assumes that the covariance matrix of the features is isotropic 
i.e. \eqn{Cov(X_i) = \sigma^2 I_p}. Setting \code{iso} to false instead assumes that 
\eqn{Cov(X_i) = \Sigma}. If known, \eqn{\sigma} can be passed in using the \code{sigma} argument 
or \eqn{\Sigma^{-1}} can be passed in the \code{SigInv} argument; otherwise, an 
estimate of \eqn{\sigma} or \eqn{\Sigma} will be used.
}
\examples{
# Simulates a 100 x 2 data set with no clusters
set.seed(1)
dat <- matrix(rnorm(200), 100, 2)

# Complete linkage hierarchical clustering
library(fastcluster)
hcl <- hclust(dist(dat, method="euclidean")^2, method="complete")

# plot dendrograms with the 1st and 2nd clusters (cut at the third level) 
# displayed in blue and orange 
plot(hcl)
rect_hier_clusters(hcl, k=3, which=1:2, border=c("blue", "orange"))

# Monte Carlo test for a difference in means between the blue and orange clusters
test_complete_hier_clusters_approx(X=dat, hcl=hcl, K=3, k1=1, k2=2, ndraws=1000)

}
\references{
Lucy L. Gao et al. "Selective inference for hierarchical clustering".
}
\seealso{
\code{\link{rect_hier_clusters}} for visualizing clusters \code{k1} and \code{k2} in the dendrogram;

\code{\link{test_hier_clusters_exact}} for exact p-values for hierarchical clustering with other linkages;

\code{\link{test_clusters_approx}} for approximate p-values for a user-specified clustering function;
}
