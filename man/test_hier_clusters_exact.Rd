% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trunc_inf.R
\name{test_hier_clusters_exact}
\alias{test_hier_clusters_exact}
\title{Exact significance test for hierarchical clustering}
\usage{
test_hier_clusters_exact(
  X,
  link,
  hcl,
  K,
  k1,
  k2,
  iso = TRUE,
  sig = NULL,
  SigInv = NULL,
  dist = NULL
)
}
\arguments{
\item{X}{\eqn{n} by \eqn{p} matrix containing numeric data.}

\item{link}{String selecting the linkage. Supported options are 
\code{"single", "average", "centroid", "ward.D", "median"}, and \code{"mcquitty"}.}

\item{hcl}{Object of the type \code{hclust} containing the hierarchical clustering of X.}

\item{K}{Integer selecting the total number of clusters.}

\item{k1, k2}{Integers selecting the clusters to test, as indexed by the results of \code{cutree(hcl, K)}.}

\item{iso}{Boolean. If \code{TRUE}, isotropic covariance matrix model, otherwise not.}

\item{sig}{Optional scalar specifying \eqn{\sigma}, relevant if \code{iso} is \code{TRUE}.}

\item{SigInv}{Optional matrix specifying \eqn{\Sigma^{-1}}, relevant if \code{iso} is \code{FALSE}.}

\item{dist}{The SQUARED Euclidean distances of matrix X}
}
\value{
\item{stat}{the test statistic: the Euclidean distance between the mean of cluster \code{k1} and the mean of cluster \code{k2}  }
\item{pval}{the p-value}
\item{trunc}{object of the type \code{Intervals} containing the conditioning set}
}
\description{
This tests the null hypothesis of no difference in means between 
clusters \code{k1} and \code{k2} at level \code{K} in a hierarchical clustering. 
(The \code{K} clusters are numbered as per the results of the \code{cutree} 
function in the \code{stats} package.)
}
\details{
In order to account for the fact that the clusters have been estimated from the data, 
the p-values are computed conditional on the fact that those clusters were estimated. 
This function computes p-values exactly via an analytic characterization of the conditioning set. 

Currently, this function supports SQUARED Euclidean distance as a measure of dissimilarity 
between observations, and the following six linkages: single, average, centroid, Ward, 
McQuitty (also known as WPGMA), and median (also kn√üown as WPGMC). 

By default, this function assumes that the covariance matrix of the features is isotropic 
i.e. \eqn{Cov(X_i) = \sigma^2 I_p}. Setting \code{iso} to \code{FALSE} instead assumes that 
\eqn{Cov(X_i) = \Sigma}. If known, \eqn{\sigma} can be passed in using the \code{sigma} argument 
or \eqn{\Sigma^{-1}} can be passed in the \code{SigInv} argument; otherwise, an 
estimate of \eqn{\sigma} or \eqn{\Sigma} will be used. 

Note that passing in the SQUARED Euclidean distance object used by \code{hclust} in using the
optional \code{dist} argument improves computational efficiency for all linkages except 
for single linkage. This may not lead to noticeable speed-ups in small data sets but 
leads to major speed-ups in large data sets. Thank you to Jesko Wagner for 
suggesting and implementing this change.
}
\examples{
# Simulates a 100 x 2 data set with three clusters
set.seed(123)
dat <- rbind(c(-1, 0), c(0, sqrt(3)), c(1, 0))[rep(1:3, length=100), ] + 
matrix(0.2*rnorm(200), 100, 2)

# Average linkage hierarchical clustering
hcl <- hclust(dist(dat, method="euclidean")^2, method="average")

# plot dendrograms with the 1st and 2nd clusters (cut at the third split) 
# displayed in blue and orange 
plot(hcl)
rect_hier_clusters(hcl, k=3, which=1:2, border=c("blue", "orange"))

# tests for a difference in means between the blue and orange clusters
test_hier_clusters_exact(X=dat, link="average", hcl=hcl, K=3, k1=1, k2=2)

}
\references{
Lucy L. Gao et al. "Selective inference for hierarchical clustering".
}
\seealso{
\code{\link{rect_hier_clusters}} for visualizing clusters \code{k1} and \code{k2} in the dendrogram;

\code{\link{test_complete_hier_clusters_approx}} for approximate p-values for complete linkage hierarchical clustering;

\code{\link{test_clusters_approx}} for approximate p-values for a user-specified clustering function;
}
